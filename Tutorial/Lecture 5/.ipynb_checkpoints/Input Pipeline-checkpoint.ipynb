{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queues and Coordinators\n",
    "Queues: important TensorFlow objects for computing tensors asynchronously in a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In input pipeline, multiple threads can help us reduce the bottleneck at the reading in data phase \n",
    "# because reading in data is a lot of waiting.\n",
    "# in using queues to prepare inputs for training a model, we have:\n",
    "# Multiple threads prepare training examples and push them in the queue.\n",
    "# A training thread executes a training op that dequeues mini-batches from the queue.\n",
    "\n",
    "# The TensorFlow Session object is designed multithreaded, so multiple threads can easily use the same session \n",
    "# and run ops in parallel.\n",
    "# In python, All threads must be able to stop together, exceptions must be caught and reported, \n",
    "# and queues must be properly closed when stopping.\n",
    "\n",
    "# TensorFlow provides two classes to help with the threading: tf.Coordinator and tf.train.QueueRunner.\n",
    "# The Coordinator class helps multiple threads stop together and report exceptions to a program \n",
    "# that waits for them to stop. The QueueRunner class is used to create a number of threads \n",
    "# cooperating to enqueue tensors in the same queue.\n",
    "\n",
    "# two main queue classes, tf.FIFOQueue and tf.RandomShuffleQueue.\n",
    "# FIFOQueue creates a queue the dequeues elements in a first in first out order, \n",
    "# while RandomShuffleQueue dequeues elements in, well, a random order.\n",
    "# These two queues support the enqueue, enqueue_many, and dequeue\n",
    "\n",
    "# A common practice is that you enqueue many examples in when you read your data, but dequeue them one by one.\n",
    "# If you want to get multiple elements at once for your batch training,\n",
    "# youâ€™ll have to use tf.train.batch or tf.train.shuffle_batch if you want to your batch to be shuffled.\n",
    "\n",
    "# There is also tf.PaddingFIFOQueue which is a FIFOQueue that supports batching variable-sized tensors by padding.\n",
    "# tf.PriorityQueue, which is a FIFOQueue whose enqueues and dequeues take in another argument: the priority\n",
    "\n",
    "# in practice, you rarely use a queue by itself, but always with string_input_producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 1000\n",
    "NUM_THREADS = 4\n",
    "# Generating some simple data\n",
    "# create 1000 random samples, each is a 1D array from the normal distribution (10, 1) \n",
    "data = 10 * np.random.randn(N_SAMPLES, 4) + 1\n",
    "# create 1000 random labels of 0 and 1\n",
    "target = np.random.randint(0, 2, size=N_SAMPLES)\n",
    "queue = tf.FIFOQueue(capacity=50, dtypes=[tf.float32, tf.int32], shapes=[[4], []])\n",
    "enqueue_op = queue.enqueue_many([data, target])\n",
    "dequeue_op = queue.dequeue()\n",
    "# create NUM_THREADS to do enqueue\n",
    "qr = tf.train.QueueRunner(queue, [enqueue_op] * NUM_THREADS)\n",
    "with tf.Session() as sess:\n",
    "# Create a coordinator, launch the queue runner threads.\n",
    "    coord = tf.train.Coordinator()\n",
    "    enqueue_threads = qr.create_threads(sess, coord=coord, start=True) \n",
    "    for step in xrange(100):   # do to 100 iterations\n",
    "        if coord.should_stop(): \n",
    "            break\n",
    "        data_batch, label_batch = sess.run(dequeue_op) \n",
    "    coord.request_stop()\n",
    "    coord.join(enqueue_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.Coordinator is used to manage threads of any thread we create, e.g., use python threading package to create threads\n",
    "import threading\n",
    "# thread body: loop until the coordinator indicates a stop was requested.\n",
    "# if some condition becomes true, ask the coordinator to stop.\n",
    "def my_loop(coord):\n",
    "    while not coord.should_stop():\n",
    "        ... do  something ... \n",
    "        if   ... some condition ...:\n",
    "            coord.request_stop() \n",
    "\n",
    "# main code: create a coordinator.\n",
    "coord = tf.Coordinator()\n",
    "# create 10 threads that run 'my_loop()'\n",
    "# you can also create threads using QueueRunner as the example above\n",
    "threads = [threading.Thread(target=my_loop, args=(coord,)) for _ in xrange(10)]\n",
    "# start the threads and wait for all of them to stop.\n",
    "for t in threads:\n",
    "    t.start()\n",
    "coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
