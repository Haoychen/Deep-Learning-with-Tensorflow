{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Issues: 1. checkpoint 2. how to control this random factor in our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.train.Saver()\n",
    "\n",
    "A good practice is to periodically save the modelâ€™s parameters after a certain number of steps.  \n",
    "So that we can restore/retrain our model from that step if need be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.train.Saver.save(sess, save_path, global_step=None, latest_filename=None, \n",
    "                    meta_graph_suffix='meta', write_meta_graph=True, write_state=True)\n",
    "\n",
    "# For example, if we want to save the variables of the graph after every 1000 training steps, we\n",
    "# do the following:\n",
    "\n",
    "# define model\n",
    "\n",
    "# create a saver object\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# launch a session to compute the graph\n",
    "with tf.Session() as sess:\n",
    "    # actual training loop\n",
    "    for step in range(training_step):\n",
    "        sess.run([optimizer])\n",
    "        \n",
    "        if (step + 1) % 100 == 0:\n",
    "            saver.save(sess, 'checkpoint_directory/model_name', global_step=model.global_step)\n",
    "            \n",
    "# global_step is the # of training steps our model has gone throught, we need to create it, initialize it\n",
    "# to 0 and set it be not trainable\n",
    "self.global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "# need to pass global_step as a parameter to the optimizer so it knows to increament it by one with each training step\n",
    "self.optimizer = tf.train.GradientDescentOptimizer(self.lr).minimize(self.loss, global_step=self.global_step)\n",
    "\n",
    "# To restore the variables, we use tf.train.Saver.restore(sess, save_path)\n",
    "saver.restore(sess, 'checkpoint/skip-gram-10000')\n",
    "\n",
    "# before load the checkpoint, could check whether the checkpoint exists\n",
    "ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "# The file checkpoint automatically updates the path to the latest checkpoint.\n",
    "\n",
    "# you can also choose what variables to store by passing them in as a list or a dict when we \n",
    "# create the saver object.\n",
    "\n",
    "v1 = tf.Variable(..., name='v1')\n",
    "v2 = tf.Variable(..., name='v2')\n",
    "# pass the variables as a dict\n",
    "saver = tf.train.Saver({'v1': v1, 'v2': v2})\n",
    "\n",
    "# pass them as a list\n",
    "saver = tf.train.Saver([v1, v2])\n",
    "\n",
    "# passing a list is equivalent to passing a dict with the variable op names # as keys\n",
    "saver = tf.train.Saver({v.op.name: v for v in [v1, v2]})\n",
    "\n",
    "\n",
    "#  Note that savers only save variables, not the entire graph, \n",
    "# so we still have to create the graph ourselves, and then load in variables. \n",
    "# The checkpoints specify the way to map from variable names to tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.summary\n",
    "\n",
    "Use TensorBoard to show all satatistics, we have a new namescope in our graph to hold all the summary ops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _create_summaries(self):\n",
    "    with tf.name_scope(\"summaries\"):\n",
    "        tf.summary.scalar(\"loss\", self.loss)\n",
    "        tf.summary.scalar(\"accuracy\", self.accuracy)\n",
    "        tf.summary.histogram(\"histogram loss\", self.loss)\n",
    "        # because you have several summaries, we should merge them all\n",
    "        # into one op to make it easier to manager\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "\n",
    "loss_batch, _, summary = sess.run([model/loss, model.optimizer, model.summary_opt],\n",
    "                                 feed_dict=feed_dict)\n",
    "\n",
    "writer.add_summary(summary, global_step=step)\n",
    "\n",
    "# you can visualize the statistics as images using tf.summary.image\n",
    "tf.summary.image(name, tensor, max_outputs=3, collections=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control randomization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorflow does not suppot random state as numpy but could control the randomization in two ways\n",
    "\n",
    "# 1. Set random seed at operation level. All random tensors allow you to pass in seed value in\n",
    "# their initialization. For example:\n",
    "my_var = tf.Variable(tf.truncated_normal((- 1.0, 1.0), stddev=0.1, seed=0))\n",
    "# Note that, session is the thing that keeps track of random state, so each new session will start\n",
    "# the random state all over again.\n",
    "c = tf.random_uniform([], -10, 10, seed=2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "print sess.run(c) # >> 3.57493 \n",
    "print sess.run(c) # >> -5.97319\n",
    "\n",
    "c = tf.random_uniform([], -10, 10, seed=2)\n",
    "with tf.Session() as sess:\n",
    "print sess.run(c) # >> 3.57493\n",
    "with tf.Session() as sess:\n",
    "print sess.run(c) # >> 3.57493\n",
    "\n",
    "# each op keeps its own seed.\n",
    "c = tf.random_uniform([], -10, 10, seed=2)\n",
    "d = tf.random_uniform([], -10, 10, seed=2)\n",
    "                \n",
    "with tf.Session() as sess:\n",
    "    print sess.run(c) # >> 3.57493 \n",
    "    print sess.run(d) # >> 3.57493\n",
    "    \n",
    "# 2. Set random seed at graph level with tf.Graph.seed\n",
    "tf.set_random_seed(seed) # just want to be able to replicate result on another graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data in Tensorflow\n",
    "Two ways to load data into Tensorflow graph:\n",
    "1. through feed_dict\n",
    "2. through readers that allow us to read tensors directly from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How feed_dict work:  Feed_dict will first send data from the storage system to the client, \n",
    "# and then from client to the worker process. This will cause the data to slow down, especially if the client is\n",
    "# on a different machine from the worker process.\n",
    "# tensorflow readers\n",
    "tf.TextLineReader\n",
    "# output the lines of a file delimited by newlines e.g. text files, CSV files\n",
    "\n",
    "tf.FixedLengthRecoredReader\n",
    "# output the entire file when all files have same fixed lenghts\n",
    "# e.g. each MNIST file has 28 * 28 pixels, CIFAR-10 32 * 32 * 3\n",
    "\n",
    "tf.WholeFileReader\n",
    "# output the entire file content\n",
    "\n",
    "tf.TFRecordReader\n",
    "# reads samples from tensorflow's own binary format (TFRecords)\n",
    "\n",
    "tf.ReaderBase\n",
    "# Allows you to create your own readers\n",
    "\n",
    "# Data can be read in as individual data examples or in batches of examples.\n",
    "\n",
    "filename_queue = tf.train.string_input_producer([\"file0.csv\", \"file1.csv\"])\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(file_queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.FIFOQueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = tf.FIFOQueue(3, \"float\")\n",
    "init = q.enqueue_many(([0., 0., 0.],))\n",
    "x = q.dequeue()\n",
    "y = x + 1\n",
    "q_inc = q.enqueue([y])\n",
    "init.run()\n",
    "q_inc.run()\n",
    "q_inc.run()\n",
    "q_inc.run()\n",
    "q_inc.run()\n",
    "\n",
    "# You can use tf.Coordinator and tf.QueueRunner to manage your queues\n",
    "# Threads & Queues\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # start populating the filename queue.\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
