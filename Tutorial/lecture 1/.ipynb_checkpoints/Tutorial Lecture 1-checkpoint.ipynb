{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph and Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow support Data Flow Graphs\n",
    "\n",
    "# phase 1: assemble a graph\n",
    "a = tf.add(2, 3) # tf automatically name the nodes when you don't explicitly name them\n",
    "# what is node? Nodes: operators, variables, and constants\n",
    "# What is edges: tensors (data)\n",
    "print a # Not 5, so how to get the value of a? Create a session, assign it to variable sess so can call it later\n",
    "        # within the session, evaluate the graph to fetch the value of a (phase 2)\n",
    "\n",
    "# phase 2: use a session to execute operations in the graph\n",
    "sess = tf.Session()  # a Session object encapsulate the environment in which Operation objects are executed, and the Tensor objects are evaluated\n",
    "print sess.run(a) # output the result 5\n",
    "sess.close # free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# More graph\n",
    "x = 2\n",
    "y = 3\n",
    "op1 = tf.add(x, y) # 5\n",
    "op2 = tf.multiply(x, y) # 6\n",
    "op3 = tf.pow(op2, op1) # 6 ^ 5\n",
    "with tf.Session() as sess:\n",
    "    op3 = sess.run(op3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It is possible to break graphs into several chunks and run them parallelly across multiple CPUs, GPUs, or devices\n",
    "# Distributed Computation\n",
    "# To put part of a graph on a specific CPU or GPU\n",
    "# Create a graph\n",
    "with tf.device('/cpu:2'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b) # Multiplies matrix a by matrix b, producing a * b, (a, b must be matrix, changed in TF 1.1 version)\n",
    "    \n",
    "# Creates a session with log_device_placement set to True\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "# Runs the op.\n",
    "print sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if want more than one graph\n",
    "# multiple graphs require multiple sessions, each will try to use all available resources by default\n",
    "# can't pass data btw them without passing them through python/numpy. which does not work in distributed\n",
    "# better to have disconnected subgraphs within one graph\n",
    "\n",
    "g = tf.Graph() # create a graph\n",
    "with g.as_default(): # add operators to a graph, set it as default\n",
    "    x = tf.add(3, 5)\n",
    "    \n",
    "with tf.Session(graph=g) as sess: # session is run on the graph g; session would be close automatically\n",
    "    print sess.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do not mix default graph and user created graphs\n",
    "g1 = tf.get_default_graph()\n",
    "g2 = tf.Graph()\n",
    "\n",
    "with g1.as_default():\n",
    "    a = tf.constant(3)\n",
    "    \n",
    "with g2.as_default():\n",
    "    b = tf.constant(5)\n",
    "\n",
    "sess = tf.Session() # run on the default graph\n",
    "print sess.run(a) # error if run(b) because default graph does not have node b\n",
    "\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    print sess.run(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why graphs?\n",
    "- save computation, only run subgraphs that lead to the values we want to fetch\n",
    "- Break computation into small, different pieces to facilitates auto-differention\n",
    "- Facilitate distributed computation, spread the work across multiple CPUs, GPUs, or devices\n",
    "- Many common machine learning models are commonly taught and visualized as directed graphs already"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "x = tf.add(a, b)\n",
    "with tf.Session() as sess:\n",
    "    # To activate TensorBoard on this program, add a line after we've built the graph, right before running the train loop\n",
    "    writer = tf.summary.FileWriter('./graphs', sess.graph)  # './graphs' is the logs_dir\n",
    "    print sess.run(x)\n",
    "\n",
    "writer.close() # close the writer when you'are done using it\n",
    "\n",
    "# Next, go to Terminal, run the program. Make sure that your present working directory is the same as where you ran your Python code.\n",
    "# python  [ yourprogram . py ]\n",
    "# tensorboard  --logdir = \"./graphs\"\n",
    "# Open your browser and go to http://localhost:6006/  (or the link you get back after running tensorboard command).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tensorflow Constant types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create constants of scalar or tensor values\n",
    "tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False)\n",
    "\n",
    "a = tf.constant([2, 2], name='vaector')\n",
    "b = tf.constant([[1, 2], [3, 4]], name='matrix')\n",
    "\n",
    "tf.zeros(shape, dtype=tf.float32, name=None)  # like numpy.zeros\n",
    "tf.zeros([2, 3], tf.int32)\n",
    "\n",
    "# like numpy.zeros_like, create a tensor of shape and type (unless type is specified) as the input_tensor but all elements are zeros.\n",
    "tf.zeros_like(tensor, dtype=None, name=None, optimize=True) # optimize: if true, attempt to statically determine the shape of 'tensor' and encode it as a constant.\n",
    "\n",
    "tf.ones(shape, dtype=tf.float32, name=None)  # like numpy.ones\n",
    "tf.ones_like(tensor, dtype=None, name=None, optimize=True) # like numpy.ones_like"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
